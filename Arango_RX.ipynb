{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JeXxryAUFyb0",
        "outputId": "667111fb-bde4-4b60-89b1-9c0098035d97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2025/02/19 23:17:43 +0000] [2514] [INFO] - adbnx_adapter: Instantiated ADBNX_Adapter with database '_system'\n",
            "INFO:adbnx_adapter:Instantiated ADBNX_Adapter with database '_system'\n",
            "[23:17:43 +0000] [INFO]: Graph 'SYNTHEA_P100' exists.\n",
            "INFO:nx_arangodb:Graph 'SYNTHEA_P100' exists.\n",
            "[23:17:44 +0000] [INFO]: Default node type set to 'allergies'\n",
            "INFO:nx_arangodb:Default node type set to 'allergies'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://276582ce6645b69e71.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://276582ce6645b69e71.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tool='use_aql' tool_input='FOR allergy IN allergies COLLECT name = allergy.name WITH COUNT INTO frequency SORT frequency DESC LIMIT 1 RETURN {name, frequency}' log='To determine the most common allergy, I need to analyze data that includes information about various allergies and their frequencies. This type of query can be addressed using the Arango Query Language (AQL) to aggregate and find the most frequent allergy. \\n\\nAction: use_aql\\nAction Input: \"FOR allergy IN allergies COLLECT name = allergy.name WITH COUNT INTO frequency SORT frequency DESC LIMIT 1 RETURN {name, frequency}\"'\n",
            "tool='use_both' tool_input=\"Find the shortest path from patient 'patients/01fd0320-1260-3613-95fb-7703f53e6a08' to patient 'patients/0dec9290-26b0-0bac-1ef0-f8b3c6cf18ba'. Also, find the total number of patients in the graph.\" log='To answer the question, I need to perform two tasks:\\n\\n1. Find the shortest path between two patients in the graph.\\n2. Find the total number of patients in the graph.\\n\\nThe first task can be accomplished using a shortest path algorithm, which is best handled by the `use_networkx` tool. The second task can be accomplished using an AQL query to count the number of patients.\\n\\nSince these tasks require one AQL query and one NetworkX algorithm, I will use the `use_both` tool.\\n\\nAction: use_both\\nAction Input: \"Find the shortest path from patient \\'patients/01fd0320-1260-3613-95fb-7703f53e6a08\\' to patient \\'patients/0dec9290-26b0-0bac-1ef0-f8b3c6cf18ba\\'. Also, find the total number of patients in the graph.\"'\n",
            "{\"aql_first\": false, \"dependent_queries\" : false, \"aql_query\": \"Find the total number of patients in the graph.\", \"networkx_query\": \"Find the shortest path from patient \\\"patients/01fd0320-1260-3613-95fb-7703f53e6a08\\\" to patient \\\"patients/0dec9290-26b0-0bac-1ef0-f8b3c6cf18ba\\\".\"}\n",
            "{'aql_first': False, 'dependent_queries': False, 'aql_query': 'Find the total number of patients in the graph.', 'networkx_query': 'Find the shortest path from patient \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\" to patient \"patients/0dec9290-26b0-0bac-1ef0-f8b3c6cf18ba\".'}\n",
            "AQL will go first? NO\n",
            "Dependent queries? NO\n",
            "AQL query: Find the total number of patients in the graph.\n",
            "NetworkX query: Find the shortest path from patient \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\" to patient \"patients/0dec9290-26b0-0bac-1ef0-f8b3c6cf18ba\".\n",
            "Python code generated by NetworkX:\n",
            "import networkx as nx\n",
            "\n",
            "# Assuming G_adb is already defined and is a NetworkX graph object\n",
            "\n",
            "# Define the source and target nodes\n",
            "source_node = \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\"\n",
            "target_node = \"patients/0dec9290-26b0-0bac-1ef0-f8b3c6cf18ba\"\n",
            "\n",
            "# Use NetworkX's shortest_path function to find the shortest path\n",
            "shortest_path = nx.shortest_path(G_adb, source=source_node, target=target_node)\n",
            "\n",
            "# Set the final result to the shortest path\n",
            "FINAL_RESULT = shortest_path\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import networkx as nx\n",
        "import nx_arangodb as nxadb\n",
        "import gradio as gr\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from adbnx_adapter import ADBNX_Adapter\n",
        "from arango import ArangoClient\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from arango.exceptions import JWTAuthError\n",
        "from langchain.tools import tool\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "@tool\n",
        "def use_aql(query: str) -> str:\n",
        "  \"\"\"This tool calls the ArangoGraphQAChain object, which enables you to\n",
        "  translate a Natural Language Query into AQL, execute\n",
        "  the query, and translate the result back into Natural Language.\n",
        "  \"\"\"\n",
        "\n",
        "  # Straight forward query\n",
        "  arango_query = f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "    I have the following graph analysis query: {query}.\n",
        "    Please provide the AQL syntax to generate the solution to the query.\n",
        "    \"\"\"\n",
        "\n",
        "  # Set up the QA Chain\n",
        "  llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "  chain = ArangoGraphQAChain.from_llm(\n",
        "    llm=llm,\n",
        "    graph=arango_graph,\n",
        "    verbose=False,\n",
        "    allow_dangerous_requests=True\n",
        "  )\n",
        "\n",
        "  # Obtain the AQL and the result\n",
        "  chain.return_aql_query = True\n",
        "  chain.return_aql_result = False\n",
        "\n",
        "  result = chain.invoke(arango_query)\n",
        "  arangoGraphQAChain_response = str(result[\"result\"])\n",
        "  arangoGraphQAChain_aql = str(result[\"aql_query\"])\n",
        "\n",
        "  return \"use_aql\", arangoGraphQAChain_response\n",
        "\n",
        "@tool\n",
        "def use_networkx(query: str) -> str:\n",
        "  \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
        "  the ArangoDB Graph. You are responsible for accepting the\n",
        "  Natural Language Query, establishing which algorithm needs to\n",
        "  be executed, executing the algorithm, and translating the results back\n",
        "  to Natural Language, with respect to the original query.\n",
        "  If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
        "  this tool.\n",
        "  \"\"\"\n",
        "\n",
        "  networkx_query = f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "    Only assume that networkx is installed, and other base python dependencies. Please do not write\n",
        "    any code that causes the iteration over all the nodes. Do not filter the collections prior to\n",
        "    executing code. Speed is very important. Use the predetermined NetworkX algorithms to perform the\n",
        "    queries - try to avoid writing unnecessary code. If a NetworkX function performs a desired algorithm,\n",
        "    please use that function rather than writing out the code.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n",
        "    Your code:\n",
        "    \"\"\"\n",
        "\n",
        "  # Get the code, clean it up and execute it\n",
        "  llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "  python_code = llm.invoke(networkx_query).content\n",
        "  cleaned_up_code = re.sub(r\"^```python\\n|```$\", \"\", python_code, flags=re.MULTILINE).strip()\n",
        "\n",
        "  print(\"Python code generated by NetworkX:\")\n",
        "  print(cleaned_up_code)\n",
        "\n",
        "  # Global variables\n",
        "  global_vars = {\"G_adb\": G_adb, \"nx\": nx, \"nxadb\": nxadb}\n",
        "  local_vars = {}\n",
        "\n",
        "  exception_raised = False\n",
        "  exception_message = \"\"\n",
        "  attempt = 1\n",
        "  MAX_ATTEMPTS = 3\n",
        "\n",
        "  try:\n",
        "    exec(cleaned_up_code, global_vars, local_vars)\n",
        "  except Exception as e:\n",
        "    exception_message = e\n",
        "    print(f\"EXEC ERROR: {e}\")\n",
        "    exception_raised = True\n",
        "\n",
        "  # Try to massage the error code\n",
        "  while exception_raised and attempt <= MAX_ATTEMPTS:\n",
        "\n",
        "      networkx_query = f\"\"\"\n",
        "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "        I have the following graph analysis query: {query}.\n",
        "        I just generated the following Python code:\n",
        "        ---\n",
        "        {python_code}\n",
        "        ---\n",
        "        But it generated the following error:\n",
        "        {exception_message}\n",
        "        Please generate the corrected code. Again, be very precise on the NetworkX algorithm you select to answer this query.\n",
        "        Think step by step. Only assume that networkx is installed, and other base python dependencies.\n",
        "        Please do not write any code that causes the iteration over all the nodes. Filter the collections as much as possible\n",
        "        in order to create code that executes quickly. Speed is very important.Always set the last\n",
        "        variable as `FINAL_RESULT`, which represents the answer to the original query. Only provide python code that I can\n",
        "        directly execute via `exec()`. Do not provide any instructions. Make sure that `FINAL_RESULT` stores a short & consice answer.\n",
        "        Avoid setting this variable to a long sequence.\n",
        "        Your code:\n",
        "        \"\"\"\n",
        "\n",
        "      # Get the code, clean it up and execute it\n",
        "      python_code = llm.invoke(networkx_query).content\n",
        "      cleaned_up_code = re.sub(r\"^```python\\n|```$\", \"\", python_code, flags=re.MULTILINE).strip()\n",
        "\n",
        "      print(\"Re-attempt #\" + str(attempt))\n",
        "      print(\"Python code generated by NetworkX:\")\n",
        "      print(cleaned_up_code)\n",
        "\n",
        "      # Global variables\n",
        "      global_vars = {\"G_adb\": G_adb, \"nx\": nx, \"nxadb\": nxadb}\n",
        "      local_vars = {}\n",
        "\n",
        "      try:\n",
        "        exec(cleaned_up_code, global_vars, local_vars)\n",
        "        exception_raised = False\n",
        "      except Exception as e:\n",
        "        exception_message = e\n",
        "        print(f\"EXEC ERROR: {e}\")\n",
        "        attempt = attempt + 1\n",
        "\n",
        "  if not exception_raised:\n",
        "    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n",
        "    return \"use_networkx\", f\"FINAL_RESULT: {FINAL_RESULT}\"\n",
        "  else:\n",
        "    return \"use_networkx\", \"The Python code produced by NetworkX could not be executed properly.\"\n",
        "\n",
        "@tool\n",
        "def use_both(query: str) -> str:\n",
        "  \"\"\"This tool is available to invoke both AQL and a NetworkX Algorithm on\n",
        "  the ArangoDB Graph. You are responsible for accepting the\n",
        "  Natural Language Query, establishing which algorithm needs to\n",
        "  be executed, executing the algorithm, and translating the results back\n",
        "  to Natural Language, with respect to the original query.\n",
        "  If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
        "  this tool. This tool should only be used when both AQL and NetworkX are necessary to solve the query.\n",
        "  Please note that this tool can only solve queries that require ONE AQL call and ONE NetworkX call. It can have\n",
        "  two, and only two, steps. If there are more steps necessary, then this tool cannot be used.\n",
        "  \"\"\"\n",
        "\n",
        "  # Break down the query into two steps\n",
        "  breakdown_prompt = f\"\"\"\n",
        "  This query: {query}\n",
        "  will use both AQL and NetworkX to complete. You will return the following four variables. Your response will only be\n",
        "  these four variables. Please do not add anything else to your response. You will not include the thought process behind\n",
        "  how you obtained the variable. You will only include the four variables in your answer.\n",
        "\n",
        "  aql_first: boolean\n",
        "  This boolean will be either true or false. It will be true if the AQL query should be executed first or false if the\n",
        "  NetworkX call should be execute first. Please only return true or false for the variable aql_first.\n",
        "\n",
        "  dependent_queries: boolean\n",
        "  This boolean will be either true or false. It will be true if the second query is dependent on the result of the first query.\n",
        "  An example would be if the second query needs a value obtained in the first query. It will be false if the second query is\n",
        "  wholly independent on the first query. An example would be a count of items that is not based on any result obtained in the\n",
        "  first query. Please only return true or false for the variable dependent_queries.\n",
        "\n",
        "  aql_query: string\n",
        "  This string will contain the portion of the query that will be executed with AQL. It will only contain the portion\n",
        "  of the query pertaining to AQL. Please do not set this variable to the actual AQL to execute. I only need the portion\n",
        "  of {query} that contains the portion that can be executed via AQL.\n",
        "\n",
        "  networkx_query: string\n",
        "  This string will contain the portion of the query that will be executed with NetworkX. It will only contain the portion\n",
        "  of the query pertaining to NetworkX. Please do not set this variable to the actual NetworkX code to execute. I only need the portion\n",
        "  of {query} that contains the portion that pertains to NetworkX.\n",
        "\n",
        "  The response will be in this format, and only this format. It will be a JSON formatted like this:\n",
        "  {{\\\"aql_first\\\": aql_first, \\\"dependent_queries\\\" : dependent_queries, \\\"aql_query\\\": aql_query, \\\"networkx_query\\\": networkx_query}}\n",
        "  It is very important that your response is formatted as described above. Please do not deviate from this format.\n",
        "  \"\"\"\n",
        "\n",
        "  llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "  result = llm.invoke(breakdown_prompt).content\n",
        "  result = re.sub(r\"^```json\\n|```$\", \"\", result, flags=re.MULTILINE).strip()\n",
        "  print(result)\n",
        "\n",
        "  # Find the three variables\n",
        "  result_json = json.loads(result)\n",
        "  print(result_json)\n",
        "\n",
        "  if len(result_json) == 4:\n",
        "\n",
        "    aql_first = result_json['aql_first']\n",
        "    dependent_queries = result_json['dependent_queries']\n",
        "    aql_query = result_json['aql_query']\n",
        "    networkx_query = result_json['networkx_query']\n",
        "\n",
        "    use_both_tool_summary = \"use_both\\n\"\n",
        "    if aql_first:\n",
        "      print(\"AQL will go first? YES\")\n",
        "      use_both_tool_summary = use_both_tool_summary + \"AQL will go first? YES\\n\"\n",
        "    else:\n",
        "      print(\"AQL will go first? NO\")\n",
        "      use_both_tool_summary = use_both_tool_summary + \"AQL will go first? NO\\n\"\n",
        "\n",
        "    if dependent_queries:\n",
        "      print(\"Dependent queries? YES\")\n",
        "      use_both_tool_summary = use_both_tool_summary + \"Dependent queries? YES\\n\"\n",
        "    else:\n",
        "      print(\"Dependent queries? NO\")\n",
        "      use_both_tool_summary = use_both_tool_summary + \"Dependent queries? NO\\n\"\n",
        "\n",
        "    print(\"AQL query: \" + aql_query)\n",
        "    print(\"NetworkX query: \" + networkx_query)\n",
        "\n",
        "    use_both_tool_summary = use_both_tool_summary + \"AQL query: \" + aql_query + \"\\n\"\n",
        "    use_both_tool_summary = use_both_tool_summary + \"NetworkX query: \" + networkx_query\n",
        "\n",
        "    if aql_first:\n",
        "      aql_result = use_aql(aql_query)\n",
        "      networkx_query_enhanced = networkx_query\n",
        "      if dependent_queries:\n",
        "        networkx_query_enhanced = f\"\"\"\n",
        "        Use the result from the AQL query above: {aql_result}\n",
        "        to run this query: {networkx_query}\n",
        "        \"\"\"\n",
        "\n",
        "      return use_both_tool_summary, use_networkx(networkx_query_enhanced)\n",
        "\n",
        "    else:\n",
        "      networkx_result = use_networkx(networkx_query)\n",
        "      aql_query_enhanced = aql_query\n",
        "      if dependent_queries:\n",
        "        aql_query_enhanced = f\"\"\"\n",
        "        Use the result from the NetworkX query above: {networkx_result}\n",
        "        to run this query: {aql_query}\n",
        "        \"\"\"\n",
        "\n",
        "      return use_both_tool_summary, use_aql(aql_query_enhanced)\n",
        "\n",
        "  else:\n",
        "    return use_both_tool_summary, \"The use_both tool could not obtain the correct answer to your query. Please try to formulate it in a different way.\"\n",
        "\n",
        "@tool\n",
        "def none_apply(query: str) -> str:\n",
        "  \"\"\"This tool is only used when the query does not apply to the Graph or its data, or when the query would\n",
        "  require more than one AQL query and more than one NetworkX algorithm. These queries would be outside the\n",
        "  realm of possibility for the program and the user must be made aware of this.\n",
        "  \"\"\"\n",
        "\n",
        "  return \"none_apply\", \"The query either 1) does not pertain to the Graph or its data or 2) requires more than one AQL and more than one NetworkX call to complete. Please try again.\"\n",
        "\n",
        "# Main program\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<<YOUR OPENAI API KEY HERE>>\"\n",
        "\n",
        "db = ArangoClient(hosts=\"https://e9a126af6ccc.arangodb.cloud:8529\").db(username=\"root\", password=\"0fUUgeTSDRCIWtZc7bL6\", verify=True)\n",
        "arango_graph = ArangoGraph(db)\n",
        "\n",
        "adbnx_adapter = ADBNX_Adapter(db)\n",
        "graph_name = \"SYNTHEA_P100\"\n",
        "G_adb = nxadb.Graph(name=graph_name, db=db)\n",
        "\n",
        "tools = [use_aql, use_networkx, use_both, none_apply]\n",
        "tool_names = [\"use_aql\", \"use_networkx\", \"use_both\", \"none_apply\"]\n",
        "\n",
        "def query_graph(query: str):\n",
        "\n",
        "    template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
        "    {tools}\n",
        "    Use the following format:\n",
        "    Question: the input question you must answer\n",
        "    Thought: you should always think about what to do\n",
        "    Action: the action to take, should be one of [{tool_names}]\n",
        "    Action Input: the input to the action\n",
        "    Observation: the result of the action\n",
        "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "    Thought: I now know the final answer\n",
        "    Final Answer: the final answer to the original input question\n",
        "    Begin!\n",
        "    Question: {input}\n",
        "    Thought:{agent_scratchpad}\"\"\"\n",
        "\n",
        "    prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "    agent = create_react_agent(llm, tools, prompt)\n",
        "    agent_executor = AgentExecutor.from_agent_and_tools(agent, tools)\n",
        "    final_state = agent.invoke({\n",
        "      \"input\" : query,\n",
        "      \"intermediate_steps\": []\n",
        "    })\n",
        "\n",
        "    print(final_state)\n",
        "\n",
        "    if not hasattr(final_state, 'tool'):\n",
        "      return none_apply(query)\n",
        "    else:\n",
        "      if final_state.tool == \"use_aql\":\n",
        "        return use_aql(query)\n",
        "      elif final_state.tool == \"use_networkx\":\n",
        "        return use_networkx(query)\n",
        "      elif final_state.tool == \"use_both\":\n",
        "        return use_both(query)\n",
        "      else:\n",
        "        return none_apply(query)\n",
        "\n",
        "gr.Interface(fn=query_graph, inputs=gr.Textbox(label=\"Enter your query here based on the SYNTHEA_P100 dataset\"), outputs=[gr.Textbox(label=\"Tool used\"), gr.Textbox(label=\"Response\")], title=\"Arango RX\").launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kXGf0J6O4z6t",
        "outputId": "20d9e2a2-3b67-4b89-bb7e-4d24c96a290a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Collecting nx_arangodb\n",
            "  Downloading nx_arangodb-1.3.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting adbnx_adapter\n",
            "  Downloading adbnx_adapter-5.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting python-arango\n",
            "  Downloading python_arango-8.1.4-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.16.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting networkx\n",
            "  Downloading networkx-3.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting phenolrs~=0.5 (from nx_arangodb)\n",
            "  Downloading phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from adbnx_adapter) (2.32.3)\n",
            "Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx_adapter) (13.9.4)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx_adapter) (75.1.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango) (2.3.0)\n",
            "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango) (1.0.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango) (2.10.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango) (8.6.1)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango) (24.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.0 (from gradio)\n",
            "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango) (3.21.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx_adapter) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx_adapter) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx_adapter) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx_adapter) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading nx_arangodb-1.3.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adbnx_adapter-5.0.6-py3-none-any.whl (21 kB)\n",
            "Downloading python_arango-8.1.4-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.5/116.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.16.1-py3-none-any.whl (62.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, networkx, mypy-extensions, marshmallow, markupsafe, httpx-sse, ffmpy, aiofiles, typing-inspect, tiktoken, starlette, safehttpx, python-arango, pydantic-settings, gradio-client, fastapi, dataclasses-json, phenolrs, gradio, adbnx_adapter, nx_arangodb, langchain_openai, langchain_community\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adbnx_adapter-5.0.6 aiofiles-23.2.1 dataclasses-json-0.6.7 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.16.1 gradio-client-1.7.0 httpx-sse-0.4.0 langchain_community-0.3.17 langchain_openai-0.3.6 markupsafe-2.1.5 marshmallow-3.26.1 mypy-extensions-1.0.0 networkx-3.4 nx_arangodb-1.3.0 phenolrs-0.5.9 pydantic-settings-2.7.1 pydub-0.25.1 python-arango-8.1.4 python-dotenv-1.0.1 python-multipart-0.0.20 ruff-0.9.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tiktoken-0.9.0 tomlkit-0.13.2 typing-inspect-0.9.0 uvicorn-0.34.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "8dbb182eb5de4d699dfe45119c5b9d77",
              "pip_warning": {
                "packages": [
                  "networkx"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install networkx nx_arangodb adbnx_adapter python-arango langchain langchain_community langchain_openai gradio"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
