{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JeXxryAUFyb0",
        "outputId": "0aa671c3-419c-48c5-a7dd-e7fdd57cfb0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025/02/22 19:30:38 +0000] [577] [INFO] - adbnx_adapter: Instantiated ADBNX_Adapter with database '_system'\n",
            "INFO:adbnx_adapter:Instantiated ADBNX_Adapter with database '_system'\n",
            "[19:30:39 +0000] [INFO]: Graph 'SYNTHEA_P100' exists.\n",
            "INFO:nx_arangodb:Graph 'SYNTHEA_P100' exists.\n",
            "[19:30:39 +0000] [INFO]: Default node type set to 'allergies'\n",
            "INFO:nx_arangodb:Default node type set to 'allergies'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1d8bfefc83231eaf7c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1d8bfefc83231eaf7c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "return_values={'output': 'The sky is typically blue during the day due to the scattering of sunlight by the atmosphere.'} log='The question about the color of the sky is not related to the ArangoDB Graph or its data. It is a general knowledge question. \\n\\nFinal Answer: The sky is typically blue during the day due to the scattering of sunlight by the atmosphere.'\n",
            "tool='use_aql' tool_input='FOR patient IN patients COLLECT WITH COUNT INTO length RETURN length' log='To determine the number of patients, I need to query the database to count the total number of patient records. This can be done using the Arango Query Language (AQL). \\n\\nAction: use_aql\\nAction Input: \"FOR patient IN patients COLLECT WITH COUNT INTO length RETURN length\"'\n",
            "tool='use_aql' tool_input='FOR allergy IN allergies COLLECT type = allergy.type WITH COUNT INTO frequency SORT frequency DESC LIMIT 1 RETURN {type, description: FIRST(FOR a IN allergies FILTER a.type == type RETURN a.description)}' log='To answer this question, I need to determine the most common type of allergy from the data and then provide its description. This can be achieved by querying the database to find the allergy type with the highest frequency and then retrieving its description. I will use the AQL tool to perform this task.\\n\\nAction: use_aql\\nAction Input: \"FOR allergy IN allergies COLLECT type = allergy.type WITH COUNT INTO frequency SORT frequency DESC LIMIT 1 RETURN {type, description: FIRST(FOR a IN allergies FILTER a.type == type RETURN a.description)}\"'\n",
            "tool='use_networkx' tool_input='Find the shortest path between \"patients/0844d9e3-a695-6ef8-f05e-229406cce635\" and \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\" and output only the number of nodes in the path.' log='To find the shortest path between two nodes in a graph, I can use a shortest path algorithm. Since the query is about finding the shortest path, I will use the NetworkX tool to perform this task.\\n\\nAction: use_networkx\\nAction Input: Find the shortest path between \"patients/0844d9e3-a695-6ef8-f05e-229406cce635\" and \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\" and output only the number of nodes in the path.'\n",
            "Python code generated by NetworkX:\n",
            "import networkx as nx\n",
            "\n",
            "# Define the source and target nodes\n",
            "source_node = \"patients/0844d9e3-a695-6ef8-f05e-229406cce635\"\n",
            "target_node = \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\"\n",
            "\n",
            "# Use NetworkX's shortest_path_length function to find the shortest path length\n",
            "shortest_path_length = nx.shortest_path_length(G_adb, source=source_node, target=target_node)\n",
            "\n",
            "# The number of nodes in the shortest path is the path length plus one (to include both endpoints)\n",
            "FINAL_RESULT = shortest_path_length + 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[19:33:11 +0000] [INFO]: Graph 'SYNTHEA_P100' load took 38.55860424041748s\n",
            "INFO:nx_arangodb:Graph 'SYNTHEA_P100' load took 38.55860424041748s\n",
            "[19:33:13 +0000] [INFO]: NXCG Graph construction took 2.416038990020752s\n",
            "INFO:nx_arangodb:NXCG Graph construction took 2.416038990020752s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tool='use_networkx' tool_input='Find the shortest path between \"patients/0844d9e3-a695-6ef8-f05e-229406cce635\" and \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\" and show all the nodes.\\n' log='To find the shortest path between two nodes in a graph, I should use a graph traversal algorithm. Since the query involves finding the shortest path, I will use the NetworkX tool to execute the shortest path algorithm.\\n\\nAction: use_networkx\\nAction Input: Find the shortest path between \"patients/0844d9e3-a695-6ef8-f05e-229406cce635\" and \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\" and show all the nodes.\\n'\n",
            "Python code generated by NetworkX:\n",
            "import networkx as nx\n",
            "\n",
            "# Define the source and target nodes\n",
            "source_node = \"patients/0844d9e3-a695-6ef8-f05e-229406cce635\"\n",
            "target_node = \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\"\n",
            "\n",
            "# Use NetworkX's shortest_path function to find the shortest path between the source and target nodes\n",
            "shortest_path = nx.shortest_path(G_adb, source=source_node, target=target_node)\n",
            "\n",
            "# Store the result in FINAL_RESULT\n",
            "FINAL_RESULT = shortest_path\n",
            "tool='use_networkx' tool_input='Find the shortest path between \"patients/0844d9e3-a695-6ef8-f05e-229406cce635\" and \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\".' log='To answer this question, I need to find the shortest path between two patients in the graph and also determine the total number of patients. The shortest path can be found using a graph algorithm, while the total number of patients can be determined using a query. Since these are two separate tasks, I will use the appropriate tools for each.\\n\\nFirst, I will find the shortest path between the two patients using a graph algorithm.\\n\\nAction: use_networkx\\nAction Input: Find the shortest path between \"patients/0844d9e3-a695-6ef8-f05e-229406cce635\" and \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\".'\n",
            "Python code generated by NetworkX:\n",
            "import networkx as nx\n",
            "\n",
            "# Find the shortest path between two patients\n",
            "source = \"patients/0844d9e3-a695-6ef8-f05e-229406cce635\"\n",
            "target = \"patients/01fd0320-1260-3613-95fb-7703f53e6a08\"\n",
            "shortest_path = nx.shortest_path(G_adb, source=source, target=target)\n",
            "\n",
            "# Count the total number of patients\n",
            "patient_nodes = [node for node in G_adb.nodes if node.startswith(\"patients/\")]\n",
            "total_patients = len(patient_nodes)\n",
            "\n",
            "# Set the final result\n",
            "FINAL_RESULT = (len(shortest_path) - 1, total_patients)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://1d8bfefc83231eaf7c.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import networkx as nx\n",
        "import nx_arangodb as nxadb\n",
        "import gradio as gr\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from adbnx_adapter import ADBNX_Adapter\n",
        "from arango import ArangoClient\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from arango.exceptions import JWTAuthError\n",
        "from langchain.tools import tool\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "@tool\n",
        "def use_aql(query: str) -> str:\n",
        "  \"\"\"This tool calls the ArangoGraphQAChain object, which enables you to\n",
        "  translate a Natural Language Query into AQL, execute\n",
        "  the query, and translate the result back into Natural Language.\n",
        "  \"\"\"\n",
        "\n",
        "  # Straight forward query\n",
        "  arango_query = f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "    I have the following graph analysis query: {query}.\n",
        "    Please provide the AQL syntax to generate the solution to the query.\n",
        "    \"\"\"\n",
        "\n",
        "  # Set up the QA Chain\n",
        "  llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "  chain = ArangoGraphQAChain.from_llm(\n",
        "    llm=llm,\n",
        "    graph=arango_graph,\n",
        "    verbose=False,\n",
        "    allow_dangerous_requests=True\n",
        "  )\n",
        "\n",
        "  # Obtain the AQL and the result\n",
        "  chain.return_aql_query = True\n",
        "  chain.return_aql_result = False\n",
        "\n",
        "  result = chain.invoke(arango_query)\n",
        "  arangoGraphQAChain_response = str(result[\"result\"])\n",
        "\n",
        "  return \"use_aql\", arangoGraphQAChain_response\n",
        "\n",
        "@tool\n",
        "def use_networkx(query: str) -> str:\n",
        "  \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
        "  the ArangoDB Graph. You are responsible for accepting the\n",
        "  Natural Language Query, establishing which algorithm needs to\n",
        "  be executed, executing the algorithm, and translating the results back\n",
        "  to Natural Language, with respect to the original query.\n",
        "  If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
        "  this tool.\n",
        "  \"\"\"\n",
        "\n",
        "  networkx_query = f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "    Only assume that networkx is installed, and other base python dependencies. Please do not write\n",
        "    any code that causes the iteration over all the nodes. Do not filter the collections prior to\n",
        "    executing code. Speed is very important. Use the predetermined NetworkX algorithms to perform the\n",
        "    queries - try to avoid writing unnecessary code. If a NetworkX function performs a desired algorithm,\n",
        "    please use that function rather than writing out the code.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n",
        "    Your code:\n",
        "    \"\"\"\n",
        "\n",
        "  # Get the code, clean it up and execute it\n",
        "  llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "  python_code = llm.invoke(networkx_query).content\n",
        "  cleaned_up_code = re.sub(r\"^```python\\n|```$\", \"\", python_code, flags=re.MULTILINE).strip()\n",
        "\n",
        "  print(\"Python code generated by NetworkX:\")\n",
        "  print(cleaned_up_code)\n",
        "\n",
        "  # Global variables\n",
        "  global_vars = {\"G_adb\": G_adb, \"nx\": nx, \"nxadb\": nxadb}\n",
        "  local_vars = {}\n",
        "\n",
        "  exception_raised = False\n",
        "  exception_message = \"\"\n",
        "  attempt = 1\n",
        "  MAX_ATTEMPTS = 3\n",
        "\n",
        "  try:\n",
        "    exec(cleaned_up_code, global_vars, local_vars)\n",
        "  except Exception as e:\n",
        "    exception_message = e\n",
        "    print(f\"EXEC ERROR: {e}\")\n",
        "    exception_raised = True\n",
        "\n",
        "  # Try to massage the error code\n",
        "  while exception_raised and attempt <= MAX_ATTEMPTS:\n",
        "\n",
        "      networkx_query = f\"\"\"\n",
        "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "        I have the following graph analysis query: {query}.\n",
        "        I just generated the following Python code:\n",
        "        ---\n",
        "        {python_code}\n",
        "        ---\n",
        "        But it generated the following error:\n",
        "        {exception_message}\n",
        "        Please generate the corrected code. Again, be very precise on the NetworkX algorithm you select to answer this query.\n",
        "        Think step by step. Only assume that networkx is installed, and other base python dependencies.\n",
        "        Please do not write any code that causes the iteration over all the nodes. Filter the collections as much as possible\n",
        "        in order to create code that executes quickly. Speed is very important.Always set the last\n",
        "        variable as `FINAL_RESULT`, which represents the answer to the original query. Only provide python code that I can\n",
        "        directly execute via `exec()`. Do not provide any instructions. Make sure that `FINAL_RESULT` stores a short & consice answer.\n",
        "        Avoid setting this variable to a long sequence.\n",
        "        Your code:\n",
        "        \"\"\"\n",
        "\n",
        "      # Get the code, clean it up and execute it\n",
        "      python_code = llm.invoke(networkx_query).content\n",
        "      cleaned_up_code = re.sub(r\"^```python\\n|```$\", \"\", python_code, flags=re.MULTILINE).strip()\n",
        "\n",
        "      print(\"Re-attempt #\" + str(attempt))\n",
        "      print(\"Python code generated by NetworkX:\")\n",
        "      print(cleaned_up_code)\n",
        "\n",
        "      # Global variables\n",
        "      global_vars = {\"G_adb\": G_adb, \"nx\": nx, \"nxadb\": nxadb}\n",
        "      local_vars = {}\n",
        "\n",
        "      try:\n",
        "        exec(cleaned_up_code, global_vars, local_vars)\n",
        "        exception_raised = False\n",
        "      except Exception as e:\n",
        "        exception_message = e\n",
        "        print(f\"EXEC ERROR: {e}\")\n",
        "        attempt = attempt + 1\n",
        "\n",
        "  if not exception_raised:\n",
        "    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n",
        "    return \"use_networkx\", f\"FINAL_RESULT: {FINAL_RESULT}\"\n",
        "  else:\n",
        "    return \"use_networkx\", \"The Python code produced by NetworkX could not be executed properly.\"\n",
        "\n",
        "@tool\n",
        "def use_both(query: str) -> str:\n",
        "  \"\"\"This tool is available to invoke both AQL and a NetworkX Algorithm on\n",
        "  the ArangoDB Graph. You are responsible for accepting the\n",
        "  Natural Language Query, establishing which algorithm needs to\n",
        "  be executed, executing the algorithm, and translating the results back\n",
        "  to Natural Language, with respect to the original query.\n",
        "  If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
        "  this tool. This tool should only be used when both AQL and NetworkX are necessary to solve the query.\n",
        "  Please note that this tool can only solve queries that require ONE AQL call and ONE NetworkX call. It can have\n",
        "  two, and only two, steps. If there are more steps necessary, then this tool cannot be used.\n",
        "  \"\"\"\n",
        "\n",
        "  # Break down the query into two steps\n",
        "  breakdown_prompt = f\"\"\"\n",
        "  This query: {query}\n",
        "  will use both AQL and NetworkX to complete. You will return the following four variables. Your response will only be\n",
        "  these four variables. Please do not add anything else to your response. You will not include the thought process behind\n",
        "  how you obtained the variable. You will only include the four variables in your answer.\n",
        "\n",
        "  aql_first: boolean\n",
        "  This boolean will be either true or false. It will be true if the AQL query should be executed first or false if the\n",
        "  NetworkX call should be execute first. Please only return true or false for the variable aql_first.\n",
        "\n",
        "  dependent_queries: boolean\n",
        "  This boolean will be either true or false. It will be true if the second query is dependent on the result of the first query.\n",
        "  An example would be if the second query needs a value obtained in the first query. It will be false if the second query is\n",
        "  wholly independent on the first query. An example would be a count of items that is not based on any result obtained in the\n",
        "  first query. Please only return true or false for the variable dependent_queries.\n",
        "\n",
        "  aql_query: string\n",
        "  This string will contain the portion of the query that will be executed with AQL. It will only contain the portion\n",
        "  of the query pertaining to AQL. Please do not set this variable to the actual AQL to execute. I only need the portion\n",
        "  of {query} that contains the portion that can be executed via AQL.\n",
        "\n",
        "  networkx_query: string\n",
        "  This string will contain the portion of the query that will be executed with NetworkX. It will only contain the portion\n",
        "  of the query pertaining to NetworkX. Please do not set this variable to the actual NetworkX code to execute. I only need the portion\n",
        "  of {query} that contains the portion that pertains to NetworkX.\n",
        "\n",
        "  The response will be in this format, and only this format. It will be a JSON formatted like this:\n",
        "  {{\\\"aql_first\\\": aql_first, \\\"dependent_queries\\\" : dependent_queries, \\\"aql_query\\\": aql_query, \\\"networkx_query\\\": networkx_query}}\n",
        "  It is very important that your response is formatted as described above. Please do not deviate from this format.\n",
        "  \"\"\"\n",
        "\n",
        "  llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "  result = llm.invoke(breakdown_prompt).content\n",
        "  result = re.sub(r\"^```json\\n|```$\", \"\", result, flags=re.MULTILINE).strip()\n",
        "  print(result)\n",
        "\n",
        "  # Find the four variables\n",
        "  result_json = json.loads(result)\n",
        "  print(result_json)\n",
        "\n",
        "  if len(result_json) == 4:\n",
        "\n",
        "    aql_first = result_json['aql_first']\n",
        "    dependent_queries = result_json['dependent_queries']\n",
        "    aql_query = result_json['aql_query']\n",
        "    networkx_query = result_json['networkx_query']\n",
        "\n",
        "    use_both_tool_summary = \"use_both\\n\"\n",
        "    if aql_first:\n",
        "      print(\"AQL will go first? YES\")\n",
        "      use_both_tool_summary = use_both_tool_summary + \"AQL will go first? YES\\n\"\n",
        "    else:\n",
        "      print(\"AQL will go first? NO\")\n",
        "      use_both_tool_summary = use_both_tool_summary + \"AQL will go first? NO\\n\"\n",
        "\n",
        "    if dependent_queries:\n",
        "      print(\"Dependent queries? YES\")\n",
        "      use_both_tool_summary = use_both_tool_summary + \"Dependent queries? YES\\n\"\n",
        "    else:\n",
        "      print(\"Dependent queries? NO\")\n",
        "      use_both_tool_summary = use_both_tool_summary + \"Dependent queries? NO\\n\"\n",
        "\n",
        "    print(\"AQL query: \" + aql_query)\n",
        "    print(\"NetworkX query: \" + networkx_query)\n",
        "\n",
        "    use_both_tool_summary = use_both_tool_summary + \"AQL query: \" + aql_query + \"\\n\"\n",
        "    use_both_tool_summary = use_both_tool_summary + \"NetworkX query: \" + networkx_query\n",
        "\n",
        "    if aql_first:\n",
        "      aql_result = use_aql(aql_query)\n",
        "      networkx_query_enhanced = networkx_query\n",
        "      if dependent_queries:\n",
        "        networkx_query_enhanced = f\"\"\"\n",
        "        Use the result from the AQL query above: {aql_result}\n",
        "        to run this query: {networkx_query}\n",
        "        \"\"\"\n",
        "\n",
        "      return use_both_tool_summary, use_networkx(networkx_query_enhanced)\n",
        "\n",
        "    else:\n",
        "      networkx_result = use_networkx(networkx_query)\n",
        "      aql_query_enhanced = aql_query\n",
        "      if dependent_queries:\n",
        "        aql_query_enhanced = f\"\"\"\n",
        "        Use the result from the NetworkX query above: {networkx_result}\n",
        "        to run this query: {aql_query}\n",
        "        \"\"\"\n",
        "\n",
        "      return use_both_tool_summary, use_aql(aql_query_enhanced)\n",
        "\n",
        "  else:\n",
        "    return use_both_tool_summary, \"The use_both tool could not obtain the correct answer to your query. Please try to formulate it in a different way.\"\n",
        "\n",
        "@tool\n",
        "def none_apply(query: str) -> str:\n",
        "  \"\"\"This tool is only used when the query does not apply to the Graph or its data, or when the query would\n",
        "  require more than one AQL query and more than one NetworkX algorithm. These queries would be outside the\n",
        "  realm of possibility for the program and the user must be made aware of this.\n",
        "  \"\"\"\n",
        "\n",
        "  return \"none_apply\", \"The query either 1) does not pertain to the Graph or its data or 2) requires more than one AQL and more than one NetworkX call to complete. Please try again.\"\n",
        "\n",
        "# Main program\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<<YOUR API KEY HERE>>\"\n",
        "\n",
        "db = ArangoClient(hosts=\"https://e9a126af6ccc.arangodb.cloud:8529\").db(username=\"root\", password=\"0fUUgeTSDRCIWtZc7bL6\", verify=True)\n",
        "arango_graph = ArangoGraph(db)\n",
        "\n",
        "adbnx_adapter = ADBNX_Adapter(db)\n",
        "graph_name = \"SYNTHEA_P100\"\n",
        "G_adb = nxadb.Graph(name=graph_name, db=db)\n",
        "\n",
        "tools = [use_aql, use_networkx, use_both, none_apply]\n",
        "tool_names = [\"use_aql\", \"use_networkx\", \"use_both\", \"none_apply\"]\n",
        "\n",
        "def query_graph(query: str):\n",
        "\n",
        "    template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
        "    {tools}\n",
        "    Use the following format:\n",
        "    Question: the input question you must answer\n",
        "    Thought: you should always think about what to do\n",
        "    Action: the action to take, should be one of [{tool_names}]\n",
        "    Action Input: the input to the action\n",
        "    Observation: the result of the action\n",
        "    ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "    Thought: I now know the final answer\n",
        "    Final Answer: the final answer to the original input question\n",
        "    Begin!\n",
        "    Question: {input}\n",
        "    Thought:{agent_scratchpad}\"\"\"\n",
        "\n",
        "    prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "    agent = create_react_agent(llm, tools, prompt)\n",
        "    agent_executor = AgentExecutor.from_agent_and_tools(agent, tools)\n",
        "    final_state = agent.invoke({\n",
        "      \"input\" : query,\n",
        "      \"intermediate_steps\": []\n",
        "    })\n",
        "\n",
        "    print(final_state)\n",
        "\n",
        "    if not hasattr(final_state, 'tool'):\n",
        "      return none_apply(query)\n",
        "    else:\n",
        "      if final_state.tool == \"use_aql\":\n",
        "        return use_aql(query)\n",
        "      elif final_state.tool == \"use_networkx\":\n",
        "        return use_networkx(query)\n",
        "      elif final_state.tool == \"use_both\":\n",
        "        return use_both(query)\n",
        "      else:\n",
        "        return none_apply(query)\n",
        "\n",
        "gr.Interface(fn=query_graph, inputs=gr.Textbox(label=\"Enter your query here based on the SYNTHEA_P100 dataset\"), outputs=[gr.Textbox(label=\"Tool used\"), gr.Textbox(label=\"Response\")], title=\"Arango RX\").launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-arango nx_arangodb gradio langchain_community langchain_openai langchain adbnx-adapter gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXGf0J6O4z6t",
        "outputId": "a6f60d98-aa25-4cb8-97c5-8ce52e492d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-arango\n",
            "  Downloading python_arango-8.1.4-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting nx_arangodb\n",
            "  Downloading nx_arangodb-1.3.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.17.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting adbnx-adapter\n",
            "  Downloading adbnx_adapter-5.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from python-arango) (2.32.3)\n",
            "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango) (1.0.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango) (2.10.1)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.11/dist-packages (from python-arango) (75.1.0)\n",
            "Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango) (8.6.1)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango) (24.2)\n",
            "Collecting networkx<=3.4,>=3.0 (from nx_arangodb)\n",
            "  Downloading networkx-3.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting phenolrs~=0.5 (from nx_arangodb)\n",
            "  Downloading phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.1 (from gradio)\n",
            "  Downloading gradio_client-1.7.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.1->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.1->gradio) (14.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.37)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.8)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter) (13.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango) (3.21.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community) (1.33)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->python-arango) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading python_arango-8.1.4-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.5/116.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nx_arangodb-1.3.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.17.1-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.1-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adbnx_adapter-5.0.6-py3-none-any.whl (21 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading networkx-3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.0-py3-none-any.whl (30 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, networkx, mypy-extensions, marshmallow, markupsafe, httpx-sse, ffmpy, aiofiles, typing-inspect, tiktoken, starlette, safehttpx, python-arango, pydantic-settings, gradio-client, fastapi, dataclasses-json, phenolrs, gradio, adbnx-adapter, nx_arangodb, langchain_openai, langchain_community\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adbnx-adapter-5.0.6 aiofiles-23.2.1 dataclasses-json-0.6.7 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.17.1 gradio-client-1.7.1 httpx-sse-0.4.0 langchain_community-0.3.18 langchain_openai-0.3.6 markupsafe-2.1.5 marshmallow-3.26.1 mypy-extensions-1.0.0 networkx-3.4 nx_arangodb-1.3.0 phenolrs-0.5.9 pydantic-settings-2.8.0 pydub-0.25.1 python-arango-8.1.4 python-dotenv-1.0.1 python-multipart-0.0.20 ruff-0.9.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tiktoken-0.9.0 tomlkit-0.13.2 typing-inspect-0.9.0 uvicorn-0.34.0\n"
          ]
        }
      ]
    }
  ]
}